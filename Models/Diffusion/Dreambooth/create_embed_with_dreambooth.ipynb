{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcBjzMkD3-ju"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate>=0.16.0 \\\n",
        "            torchvision \\\n",
        "            transformers>=4.25.1 \\\n",
        "            ftfy \\\n",
        "            tensorboard \\\n",
        "            Jinja2 \\\n",
        "            peft==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfnPGvFM4LbN",
        "outputId": "2880fa02-06c2-4421-8379-7ae2316d736d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Collecting peft\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
            "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.7.0\n",
            "    Uninstalling peft-0.7.0:\n",
            "      Successfully uninstalled peft-0.7.0\n",
            "Successfully installed peft-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "%cd diffusers\n",
        "!pip install -e .\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us1gVr3y4rE7",
        "outputId": "937079bb-1baa-470a-aaae-0fa1b6fdba0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 91190, done.\u001b[K\n",
            "remote: Counting objects: 100% (821/821), done.\u001b[K\n",
            "remote: Compressing objects: 100% (418/418), done.\u001b[K\n",
            "remote: Total 91190 (delta 676), reused 407 (delta 401), pack-reused 90369 (from 5)\u001b[K\n",
            "Receiving objects: 100% (91190/91190), 67.89 MiB | 34.78 MiB/s, done.\n",
            "Resolving deltas: 100% (66918/66918), done.\n",
            "/content/diffusers\n",
            "Obtaining file:///content/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (0.30.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0) (11.2.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.34.0.dev0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0) (2025.4.26)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.34.0.dev0-0.editable-py3-none-any.whl size=11365 sha256=45ef32109780624cdc2aacb1875ef930ad1f0b405b48a22ab6207029ff9de72b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uadxi4jj/wheels/30/15/ca/ab6e88c89d6ba7047b3f155894c6c346e7cf06067fd132ae62\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.33.1\n",
            "    Uninstalling diffusers-0.33.1:\n",
            "      Successfully uninstalled diffusers-0.33.1\n",
            "Successfully installed diffusers-0.34.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r-afgBKMAl2",
        "outputId": "77880691-87b0-4117-9700-3d935a1d4336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/dreambooth_checkpointss/output\n",
        "!mkdir -p /content/drive/MyDrive/ClassImages\n"
      ],
      "metadata": {
        "id": "QUj5gSso45bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch examples/dreambooth/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --instance_data_dir=\"/content/images\" \\\n",
        "  --output_dir=\"/content/checkpoints\" \\\n",
        "  --instance_prompt=\"Pixar style little girl <wucs>\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=500 \\\n",
        "  --with_prior_preservation \\\n",
        "  --prior_loss_weight=1.0 \\\n",
        "  --class_prompt=\"Pixar style little girl\" \\\n",
        "  --num_class_images=100 \\\n",
        "  --class_data_dir=\"/content/class_images\" \\\n",
        "  --checkpointing_steps=500 \\\n",
        "  --mixed_precision=\"fp16\"\\\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDGP8Gds4-ob",
        "outputId": "dc6742cf-8488-4fee-cc2a-b294af127fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-09 13:09:30.106228: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-09 13:09:30.123440: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746796170.144234    2572 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746796170.151022    2572 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-09 13:09:30.174223: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "05/09/2025 13:09:35 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "model_index.json: 100% 541/541 [00:00<00:00, 3.52MB/s]\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]\n",
            "config.json: 100% 617/617 [00:00<00:00, 3.88MB/s]\n",
            "\n",
            "special_tokens_map.json: 100% 472/472 [00:00<00:00, 4.53MB/s]\n",
            "\n",
            "merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 806/806 [00:00<00:00, 6.38MB/s]\n",
            "\n",
            "\n",
            "\n",
            "preprocessor_config.json: 100% 342/342 [00:00<00:00, 2.81MB/s]\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:02,  5.80it/s]\n",
            "\n",
            "\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 7.64MB/s]\n",
            "vocab.json: 100% 1.06M/1.06M [00:00<00:00, 13.6MB/s]\n",
            "\n",
            "scheduler_config.json: 100% 308/308 [00:00<00:00, 2.64MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 100% 547/547 [00:00<00:00, 5.03MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 10.5M/492M [00:00<00:04, 97.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "config.json: 100% 743/743 [00:00<00:00, 5.34MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 10.5M/3.44G [00:00<00:35, 96.4MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   6% 31.5M/492M [00:00<00:02, 160MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   3% 10.5M/335M [00:00<00:03, 93.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  13% 62.9M/492M [00:00<00:02, 210MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 41.9M/3.44G [00:00<00:18, 183MB/s] \u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 41.9M/335M [00:00<00:01, 185MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  19% 94.4M/492M [00:00<00:01, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 73.4M/3.44G [00:00<00:15, 214MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  22% 73.4M/335M [00:00<00:01, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  26% 126M/492M [00:00<00:01, 236MB/s] \u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   3% 105M/3.44G [00:00<00:14, 229MB/s] \u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  31% 105M/335M [00:00<00:00, 241MB/s] \u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   4% 136M/3.44G [00:00<00:13, 239MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  32% 157M/492M [00:00<00:01, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  41% 136M/335M [00:00<00:00, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  38% 189M/492M [00:00<00:01, 251MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   5% 168M/3.44G [00:00<00:13, 245MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  50% 168M/335M [00:00<00:00, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  45% 220M/492M [00:00<00:01, 259MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   6% 199M/3.44G [00:00<00:13, 249MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  51% 252M/492M [00:01<00:00, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  60% 199M/335M [00:00<00:00, 248MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 231M/3.44G [00:00<00:12, 252MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  58% 283M/492M [00:01<00:00, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  69% 231M/335M [00:00<00:00, 248MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   8% 262M/3.44G [00:01<00:12, 249MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  64% 315M/492M [00:01<00:00, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  78% 262M/335M [00:01<00:00, 242MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 294M/3.44G [00:01<00:12, 252MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  70% 346M/492M [00:01<00:00, 275MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  88% 294M/335M [00:01<00:00, 246MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 325M/3.44G [00:01<00:12, 253MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  77% 377M/492M [00:01<00:00, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  97% 325M/335M [00:01<00:00, 246MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 357M/3.44G [00:01<00:12, 253MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 236MB/s]\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  11% 388M/3.44G [00:01<00:11, 259MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  89% 440M/492M [00:01<00:00, 275MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 419M/3.44G [00:01<00:11, 261MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  96% 472M/492M [00:01<00:00, 277MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors: 100% 492M/492M [00:01<00:00, 257MB/s]\n",
            "Fetching 13 files:  38% 5/13 [00:02<00:03,  2.30it/s]\n",
            "diffusion_pytorch_model.safetensors:  14% 482M/3.44G [00:01<00:10, 270MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  15% 514M/3.44G [00:02<00:10, 268MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 545M/3.44G [00:02<00:10, 268MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 577M/3.44G [00:02<00:10, 265MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 608M/3.44G [00:02<00:10, 261MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  19% 640M/3.44G [00:02<00:10, 261MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 671M/3.44G [00:02<00:10, 260MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 703M/3.44G [00:02<00:10, 267MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  21% 734M/3.44G [00:02<00:10, 267MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  22% 765M/3.44G [00:03<00:09, 272MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 797M/3.44G [00:03<00:09, 277MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 828M/3.44G [00:03<00:09, 272MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 860M/3.44G [00:03<00:09, 277MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  26% 891M/3.44G [00:03<00:09, 281MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 923M/3.44G [00:03<00:08, 282MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  28% 954M/3.44G [00:03<00:08, 281MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 986M/3.44G [00:03<00:08, 286MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  30% 1.02G/3.44G [00:03<00:08, 286MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  30% 1.05G/3.44G [00:04<00:08, 286MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  31% 1.08G/3.44G [00:04<00:08, 290MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  32% 1.11G/3.44G [00:04<00:07, 295MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  33% 1.14G/3.44G [00:04<00:07, 296MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  34% 1.17G/3.44G [00:04<00:07, 291MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  35% 1.21G/3.44G [00:04<00:07, 284MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  36% 1.24G/3.44G [00:04<00:07, 284MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  37% 1.27G/3.44G [00:04<00:07, 279MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  38% 1.30G/3.44G [00:04<00:07, 279MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  39% 1.33G/3.44G [00:05<00:07, 275MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  40% 1.36G/3.44G [00:05<00:07, 271MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 1.39G/3.44G [00:05<00:07, 276MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 1.43G/3.44G [00:05<00:07, 277MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  42% 1.46G/3.44G [00:05<00:07, 280MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  43% 1.49G/3.44G [00:05<00:06, 282MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  44% 1.52G/3.44G [00:05<00:06, 286MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  45% 1.55G/3.44G [00:05<00:06, 284MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  46% 1.58G/3.44G [00:05<00:06, 288MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  47% 1.61G/3.44G [00:05<00:06, 289MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  48% 1.65G/3.44G [00:06<00:06, 292MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  49% 1.68G/3.44G [00:06<00:06, 292MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  50% 1.71G/3.44G [00:06<00:06, 286MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  51% 1.74G/3.44G [00:06<00:06, 279MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  52% 1.77G/3.44G [00:06<00:06, 277MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  52% 1.80G/3.44G [00:06<00:05, 278MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  53% 1.84G/3.44G [00:06<00:05, 272MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  54% 1.87G/3.44G [00:06<00:05, 267MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  55% 1.90G/3.44G [00:07<00:05, 262MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  56% 1.93G/3.44G [00:07<00:05, 267MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  57% 1.96G/3.44G [00:07<00:05, 271MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  58% 1.99G/3.44G [00:07<00:05, 266MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 2.02G/3.44G [00:07<00:05, 271MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  60% 2.06G/3.44G [00:07<00:05, 273MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  61% 2.09G/3.44G [00:07<00:04, 270MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  62% 2.12G/3.44G [00:07<00:04, 270MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 2.15G/3.44G [00:07<00:04, 279MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 2.18G/3.44G [00:08<00:04, 283MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  64% 2.21G/3.44G [00:08<00:04, 283MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  65% 2.24G/3.44G [00:08<00:04, 290MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  66% 2.28G/3.44G [00:08<00:04, 288MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  67% 2.31G/3.44G [00:08<00:03, 290MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  68% 2.34G/3.44G [00:08<00:03, 293MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  69% 2.37G/3.44G [00:08<00:03, 293MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  70% 2.40G/3.44G [00:08<00:03, 296MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  71% 2.43G/3.44G [00:08<00:03, 297MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 2.46G/3.44G [00:09<00:03, 298MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  73% 2.50G/3.44G [00:09<00:03, 299MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  74% 2.53G/3.44G [00:09<00:03, 296MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  74% 2.56G/3.44G [00:09<00:02, 295MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  75% 2.59G/3.44G [00:09<00:03, 282MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  76% 2.62G/3.44G [00:09<00:02, 280MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  77% 2.65G/3.44G [00:09<00:02, 285MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  78% 2.68G/3.44G [00:09<00:02, 284MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  79% 2.72G/3.44G [00:09<00:02, 283MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  80% 2.75G/3.44G [00:10<00:02, 284MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  81% 2.78G/3.44G [00:10<00:02, 282MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  82% 2.81G/3.44G [00:10<00:02, 284MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  83% 2.84G/3.44G [00:10<00:02, 282MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  84% 2.87G/3.44G [00:10<00:02, 283MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  84% 2.90G/3.44G [00:10<00:01, 284MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  85% 2.94G/3.44G [00:10<00:01, 279MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  86% 2.97G/3.44G [00:10<00:01, 285MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  87% 3.00G/3.44G [00:10<00:01, 291MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  88% 3.03G/3.44G [00:10<00:01, 296MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  89% 3.06G/3.44G [00:11<00:01, 292MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  90% 3.09G/3.44G [00:11<00:01, 294MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 3.12G/3.44G [00:11<00:01, 295MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  92% 3.16G/3.44G [00:11<00:00, 293MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  93% 3.19G/3.44G [00:11<00:00, 286MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  94% 3.22G/3.44G [00:11<00:00, 281MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  95% 3.25G/3.44G [00:11<00:00, 269MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  95% 3.28G/3.44G [00:11<00:00, 266MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  96% 3.31G/3.44G [00:12<00:00, 267MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  97% 3.34G/3.44G [00:12<00:00, 268MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  98% 3.38G/3.44G [00:12<00:00, 266MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  99% 3.41G/3.44G [00:12<00:00, 268MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [00:12<00:00, 275MB/s]\n",
            "Fetching 13 files: 100% 13/13 [00:12<00:00,  1.02it/s]\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00,  4.81it/s]Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Instantiating UNet2DConditionModel model under default dtype torch.float16.\n",
            "{'time_embedding_type', 'addition_embed_type_num_heads', 'cross_attention_norm', 'transformer_layers_per_block', 'attention_type', 'resnet_skip_time_act', 'mid_block_type', 'dropout', 'dual_cross_attention', 'reverse_transformer_layers_per_block', 'encoder_hid_dim_type', 'upcast_attention', 'encoder_hid_dim', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'addition_embed_type', 'addition_time_embed_dim', 'class_embeddings_concat', 'conv_in_kernel', 'num_class_embeds', 'num_attention_heads', 'class_embed_type', 'time_embedding_act_fn', 'only_cross_attention', 'time_embedding_dim', 'timestep_post_act', 'mid_block_only_cross_attention', 'resnet_time_scale_shift', 'conv_out_kernel', 'use_linear_projection', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/unet.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...:  67% 4/6 [00:01<00:01,  1.83it/s]Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...:  83% 5/6 [00:02<00:00,  2.39it/s]Instantiating AutoencoderKL model under default dtype torch.float16.\n",
            "{'latents_std', 'shift_factor', 'use_post_quant_conv', 'use_quant_conv', 'mid_block_add_attention', 'latents_mean', 'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 6/6 [00:02<00:00,  2.62it/s]\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "05/09/2025 13:09:50 - INFO - __main__ - Number of class images to sample: 100.\n",
            "Generating class images: 100% 25/25 [01:27<00:00,  3.50s/it]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'prediction_type', 'rescale_betas_zero_snr', 'sample_max_value', 'variance_type', 'thresholding', 'timestep_spacing', 'dynamic_thresholding_ratio', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'shift_factor', 'use_post_quant_conv', 'use_quant_conv', 'mid_block_add_attention', 'latents_mean', 'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "{'time_embedding_type', 'addition_embed_type_num_heads', 'cross_attention_norm', 'transformer_layers_per_block', 'attention_type', 'resnet_skip_time_act', 'mid_block_type', 'dropout', 'dual_cross_attention', 'reverse_transformer_layers_per_block', 'encoder_hid_dim_type', 'upcast_attention', 'encoder_hid_dim', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'addition_embed_type', 'addition_time_embed_dim', 'class_embeddings_concat', 'conv_in_kernel', 'num_class_embeds', 'num_attention_heads', 'class_embed_type', 'time_embedding_act_fn', 'only_cross_attention', 'time_embedding_dim', 'timestep_post_act', 'mid_block_only_cross_attention', 'resnet_time_scale_shift', 'conv_out_kernel', 'use_linear_projection', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "05/09/2025 13:11:22 - INFO - __main__ - ***** Running training *****\n",
            "05/09/2025 13:11:22 - INFO - __main__ -   Num examples = 100\n",
            "05/09/2025 13:11:22 - INFO - __main__ -   Num batches each epoch = 100\n",
            "05/09/2025 13:11:22 - INFO - __main__ -   Num Epochs = 20\n",
            "05/09/2025 13:11:22 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "05/09/2025 13:11:22 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "05/09/2025 13:11:22 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
            "05/09/2025 13:11:22 - INFO - __main__ -   Total optimization steps = 500\n",
            "Steps: 100% 500/500 [07:03<00:00,  1.19it/s, loss=0.362, lr=2e-6]05/09/2025 13:18:26 - INFO - accelerate.accelerator - Saving current state to /content/checkpoints/checkpoint-500\n",
            "Configuration saved in /content/checkpoints/checkpoint-500/unet/config.json\n",
            "Model weights saved in /content/checkpoints/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
            "05/09/2025 13:18:54 - INFO - accelerate.checkpointing - Optimizer state saved in /content/checkpoints/checkpoint-500/optimizer.bin\n",
            "05/09/2025 13:18:54 - INFO - accelerate.checkpointing - Scheduler state saved in /content/checkpoints/checkpoint-500/scheduler.bin\n",
            "05/09/2025 13:18:54 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/checkpoints/checkpoint-500/sampler.bin\n",
            "05/09/2025 13:18:54 - INFO - accelerate.checkpointing - Sampler state for dataloader 1 saved in /content/checkpoints/checkpoint-500/sampler_1.bin\n",
            "05/09/2025 13:18:54 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/checkpoints/checkpoint-500/scaler.pt\n",
            "05/09/2025 13:18:54 - INFO - accelerate.checkpointing - Random states saved in /content/checkpoints/checkpoint-500/random_states_0.pkl\n",
            "05/09/2025 13:18:54 - INFO - __main__ - Saved state to /content/checkpoints/checkpoint-500\n",
            "Steps: 100% 500/500 [07:31<00:00,  1.19it/s, loss=0.687, lr=2e-6]\n",
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "model.safetensors:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "config.json: 100% 4.72k/4.72k [00:00<00:00, 28.1MB/s]\n",
            "\n",
            "Fetching 11 files:  27% 3/11 [00:00<00:00, 17.16it/s]\u001b[A\n",
            "\n",
            "model.safetensors:   1% 10.5M/1.22G [00:00<00:12, 96.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   3% 41.9M/1.22G [00:00<00:06, 183MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   6% 73.4M/1.22G [00:00<00:05, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   9% 105M/1.22G [00:00<00:04, 247MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  11% 136M/1.22G [00:00<00:04, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  14% 168M/1.22G [00:00<00:04, 257MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  16% 199M/1.22G [00:00<00:03, 264MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  19% 231M/1.22G [00:00<00:03, 267MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  22% 262M/1.22G [00:01<00:03, 270MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  24% 294M/1.22G [00:01<00:03, 271MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  27% 325M/1.22G [00:01<00:03, 274MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  29% 357M/1.22G [00:01<00:03, 270MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  32% 388M/1.22G [00:01<00:03, 261MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  34% 419M/1.22G [00:01<00:03, 257MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  37% 451M/1.22G [00:01<00:03, 254MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  40% 482M/1.22G [00:01<00:02, 251MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  42% 514M/1.22G [00:02<00:02, 251MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  45% 545M/1.22G [00:02<00:02, 253MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  47% 577M/1.22G [00:02<00:02, 256MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  50% 608M/1.22G [00:02<00:02, 254MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  53% 640M/1.22G [00:02<00:02, 252MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  55% 671M/1.22G [00:02<00:02, 253MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  58% 703M/1.22G [00:02<00:02, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  60% 734M/1.22G [00:02<00:01, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  63% 765M/1.22G [00:03<00:01, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  66% 797M/1.22G [00:03<00:01, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  68% 828M/1.22G [00:03<00:01, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  71% 860M/1.22G [00:03<00:01, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  73% 891M/1.22G [00:03<00:01, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  76% 923M/1.22G [00:03<00:01, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  78% 954M/1.22G [00:03<00:01, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  81% 986M/1.22G [00:03<00:00, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  84% 1.02G/1.22G [00:04<00:00, 251MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  86% 1.05G/1.22G [00:04<00:00, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  89% 1.08G/1.22G [00:04<00:00, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  91% 1.11G/1.22G [00:04<00:00, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 1.14G/1.22G [00:04<00:00, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  97% 1.17G/1.22G [00:04<00:00, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 1.22G/1.22G [00:04<00:00, 250MB/s]\n",
            "\n",
            "Fetching 11 files: 100% 11/11 [00:05<00:00,  2.19it/s]\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00, 14.29it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'latents_std', 'shift_factor', 'use_post_quant_conv', 'use_quant_conv', 'mid_block_add_attention', 'latents_mean', 'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00, 17.49it/s]\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Configuration saved in /content/checkpoints/vae/config.json\n",
            "Model weights saved in /content/checkpoints/vae/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in /content/checkpoints/unet/config.json\n",
            "Model weights saved in /content/checkpoints/unet/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in /content/checkpoints/scheduler/scheduler_config.json\n",
            "Configuration saved in /content/checkpoints/model_index.json\n",
            "Steps: 100% 500/500 [07:53<00:00,  1.06it/s, loss=0.687, lr=2e-6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch examples/dreambooth/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --instance_data_dir=\"/content/images\" \\\n",
        "  --output_dir=\"/content/checkpoints\" \\\n",
        "  --instance_prompt=\"Pixar style little girl <wucs>\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=800 \\\n",
        "  --with_prior_preservation \\\n",
        "  --prior_loss_weight=1.0 \\\n",
        "  --class_prompt=\"Pixar style little girl\" \\\n",
        "  --num_class_images=100 \\\n",
        "  --class_data_dir=\"/content/class_images\" \\\n",
        "  --checkpointing_steps=300 \\\n",
        "  --mixed_precision=\"fp16\"\\\n",
        "  --resume_from_checkpoint=\"/content/checkpoints/checkpoint-500\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTunZci0NKNU",
        "outputId": "350c31ab-d220-4b8f-85ff-ab62592d2550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-09 13:29:11.069588: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-09 13:29:11.088245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746797351.110765   10053 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746797351.117467   10053 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-09 13:29:11.140183: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "05/09/2025 13:29:15 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'prediction_type', 'timestep_spacing', 'rescale_betas_zero_snr', 'variance_type', 'dynamic_thresholding_ratio', 'clip_sample_range', 'sample_max_value', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'force_upcast', 'use_quant_conv', 'scaling_factor', 'use_post_quant_conv', 'latents_std', 'shift_factor', 'mid_block_add_attention'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "{'num_attention_heads', 'cross_attention_norm', 'conv_out_kernel', 'time_cond_proj_dim', 'conv_in_kernel', 'class_embeddings_concat', 'transformer_layers_per_block', 'reverse_transformer_layers_per_block', 'addition_embed_type_num_heads', 'dual_cross_attention', 'attention_type', 'upcast_attention', 'timestep_post_act', 'addition_time_embed_dim', 'time_embedding_act_fn', 'encoder_hid_dim_type', 'use_linear_projection', 'addition_embed_type', 'time_embedding_dim', 'encoder_hid_dim', 'resnet_out_scale_factor', 'dropout', 'resnet_skip_time_act', 'projection_class_embeddings_input_dim', 'mid_block_type', 'time_embedding_type', 'resnet_time_scale_shift', 'class_embed_type', 'mid_block_only_cross_attention', 'only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "05/09/2025 13:29:19 - INFO - __main__ - ***** Running training *****\n",
            "05/09/2025 13:29:19 - INFO - __main__ -   Num examples = 100\n",
            "05/09/2025 13:29:19 - INFO - __main__ -   Num batches each epoch = 100\n",
            "05/09/2025 13:29:19 - INFO - __main__ -   Num Epochs = 32\n",
            "05/09/2025 13:29:19 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "05/09/2025 13:29:19 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "05/09/2025 13:29:19 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
            "05/09/2025 13:29:19 - INFO - __main__ -   Total optimization steps = 800\n",
            "Resuming from checkpoint checkpoint-500\n",
            "05/09/2025 13:29:19 - INFO - accelerate.accelerator - Loading states from /content/checkpoints/checkpoint-500\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at /content/checkpoints/checkpoint-500.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "05/09/2025 13:29:20 - INFO - accelerate.checkpointing - All model weights loaded successfully\n",
            "05/09/2025 13:29:26 - INFO - accelerate.checkpointing - All optimizer states loaded successfully\n",
            "05/09/2025 13:29:26 - INFO - accelerate.checkpointing - All scheduler states loaded successfully\n",
            "05/09/2025 13:29:26 - INFO - accelerate.checkpointing - All dataloader sampler states loaded successfully\n",
            "05/09/2025 13:29:26 - INFO - accelerate.checkpointing - GradScaler state loaded successfully\n",
            "05/09/2025 13:29:26 - INFO - accelerate.checkpointing - All random states loaded successfully\n",
            "05/09/2025 13:29:26 - INFO - accelerate.accelerator - Loading in 0 custom states\n",
            "Steps:  75% 600/800 [01:26<02:50,  1.17it/s, loss=0.31, lr=2e-6]05/09/2025 13:30:52 - INFO - accelerate.accelerator - Saving current state to /content/checkpoints/checkpoint-600\n",
            "Configuration saved in /content/checkpoints/checkpoint-600/unet/config.json\n",
            "Model weights saved in /content/checkpoints/checkpoint-600/unet/diffusion_pytorch_model.safetensors\n",
            "05/09/2025 13:31:20 - INFO - accelerate.checkpointing - Optimizer state saved in /content/checkpoints/checkpoint-600/optimizer.bin\n",
            "05/09/2025 13:31:24 - INFO - accelerate.checkpointing - Scheduler state saved in /content/checkpoints/checkpoint-600/scheduler.bin\n",
            "05/09/2025 13:31:24 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/checkpoints/checkpoint-600/sampler.bin\n",
            "05/09/2025 13:31:24 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/checkpoints/checkpoint-600/scaler.pt\n",
            "05/09/2025 13:31:24 - INFO - accelerate.checkpointing - Random states saved in /content/checkpoints/checkpoint-600/random_states_0.pkl\n",
            "05/09/2025 13:31:24 - INFO - __main__ - Saved state to /content/checkpoints/checkpoint-600\n",
            "Steps: 100% 800/800 [04:47<00:00,  1.18it/s, loss=0.258, lr=2e-6] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A{'latents_mean', 'force_upcast', 'use_quant_conv', 'scaling_factor', 'use_post_quant_conv', 'latents_std', 'shift_factor', 'mid_block_add_attention'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00, 13.21it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00, 18.81it/s]\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Configuration saved in /content/checkpoints/vae/config.json\n",
            "Model weights saved in /content/checkpoints/vae/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in /content/checkpoints/unet/config.json\n",
            "Model weights saved in /content/checkpoints/unet/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in /content/checkpoints/scheduler/scheduler_config.json\n",
            "Configuration saved in /content/checkpoints/model_index.json\n",
            "Steps: 100% 800/800 [05:05<00:00,  1.02s/it, loss=0.258, lr=2e-6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh /content/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IrEvuQXRb4u",
        "outputId": "df6a7741-9835-411c-fb96-198ba68f2032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "du: cannot access '/content/checkpoints': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/step600_model"
      ],
      "metadata": {
        "id": "M_2w0HhTTLO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/checkpoints/checkpoint-600/unet /content/step600_model/\n",
        "!cp -r /content/checkpoints/vae /content/step600_model/\n",
        "!cp -r /content/checkpoints/text_encoder /content/step600_model/\n",
        "!cp -r /content/checkpoints/tokenizer /content/step600_model/\n",
        "!cp -r /content/checkpoints/scheduler /content/step600_model/\n",
        "!cp -r /content/checkpoints/feature_extractor /content/step600_model/\n",
        "!cp -r /content/checkpoints/safety_checker /content/step600_model/\n",
        "!cp /content/checkpoints/model_index.json /content/step600_model/\n"
      ],
      "metadata": {
        "id": "FmFuMP12TMKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh /content/step600_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koxHyM3zTvn_",
        "outputId": "014b04b0-171d-4225-bce9-9838814f02a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.9G\t/content/step600_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/step600_model /content/drive/MyDrive/DreamBooth_step600"
      ],
      "metadata": {
        "id": "hDBtHOlGV-c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYM1K9QgUGLY",
        "outputId": "0385717a-747f-4266-c134-394e1ac68097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}